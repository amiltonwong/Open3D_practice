{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global registration\n",
    "http://www.open3d.org/docs/tutorial/Advanced/global_registration.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both ICP registration and Colored point cloud registration are known as **local registration** methods because they rely on a rough alignment as initialization. This tutorial shows another class of registration methods, known as global registration. This family of algorithms **do not require an alignment for initialization**. They usually produce less tight alignment results and are used as initialization of the local methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/Python/Tutorial/Advanced/global_registration.py\n",
    "\n",
    "from open3d import *\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    # source is yellow\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    # target is cyan (blue)\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "This script reads a source point cloud and a target point cloud from two files. They are misaligned with an identity matrix as transformation.\n",
    "**(misalignment)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n"
     ]
    }
   ],
   "source": [
    "# in prepare_dataset function\n",
    "\n",
    "print(\":: Load two point clouds and disturb initial pose.\")\n",
    "source = read_point_cloud(\"/data/code6/Open3D/build/lib/TestData/ICP/cloud_bin_0.pcd\")\n",
    "target = read_point_cloud(\"/data/code6/Open3D/build/lib/TestData/ICP/cloud_bin_1.pcd\")\n",
    "# create a wrong transformation.\n",
    "trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0],\n",
    "                        [1.0, 0.0, 0.0, 0.0],\n",
    "                        [0.0, 1.0, 0.0, 0.0],\n",
    "                        [0.0, 0.0, 0.0, 1.0]])\n",
    "# apply the wrong transformation on source point cloud.\n",
    "# That means source point cloud is very different to target point cloud in terms of transformation\n",
    "source.transform(trans_init)\n",
    "# draws the source and target point cloud. np.identity(4) as no change\n",
    "draw_registration_result(source, target, np.identity(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source is yellow, target is cyan (blue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"initial_t12.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract geometric feature\n",
    "We down sample the point cloud, estimate normals, then compute a FPFH feature for each point. The FPFH feature is a 33-dimensional vector that describes the local geometric property of a point. A nearest neighbor query in the 33-dimensinal space can return points with similar local geometric structures. See [Rasu2009] for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full prepare_dataset function\n",
    "\n",
    "def prepare_dataset(voxel_size):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "    source = read_point_cloud(\"/data/code6/Open3D/build/lib/TestData/ICP/cloud_bin_0.pcd\")\n",
    "    target = read_point_cloud(\"/data/code6/Open3D/build/lib/TestData/ICP/cloud_bin_1.pcd\")\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0],\n",
    "                            [1.0, 0.0, 0.0, 0.0],\n",
    "                            [0.0, 1.0, 0.0, 0.0],\n",
    "                            [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    source_down = voxel_down_sample(source, voxel_size)\n",
    "    target_down = voxel_down_sample(target, voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    estimate_normals(source_down, KDTreeSearchParamHybrid(\n",
    "            radius = radius_normal, max_nn = 30))\n",
    "    estimate_normals(target_down, KDTreeSearchParamHybrid(\n",
    "            radius = radius_normal, max_nn = 30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    source_fpfh = compute_fpfh_feature(source_down,\n",
    "            KDTreeSearchParamHybrid(radius = radius_feature, max_nn = 100))\n",
    "    target_fpfh = compute_fpfh_feature(target_down,\n",
    "            KDTreeSearchParamHybrid(radius = radius_feature, max_nn = 100))\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANSAC\n",
    "We use RANSAC for global registration. In each RANSAC iteration, `ransac_n` random points are picked from the source point cloud. Their corresponding points in the target point cloud are detected by querying the nearest neighbor in the 33-dimensional FPFH feature space. A pruning step takes fast pruning algorithms to quickly reject false matches early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_global_registration(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = registration_ransac_based_on_feature_matching(\n",
    "            source_down, target_down, source_fpfh, target_fpfh, 0.075,\n",
    "            TransformationEstimationPointToPoint(False), 4,\n",
    "            [CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            CorrespondenceCheckerBasedOnDistance(0.075)],\n",
    "            RANSACConvergenceCriteria(4000000, 500))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.050,\n",
      "   we use a liberal distance threshold 0.075.\n",
      "RegistrationResult with fitness = 0.677521, inlier_rmse = 0.032672, and correspondence_set size of 3225\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 0.05 # means 5cm for the dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = \\\n",
    "        prepare_dataset(voxel_size)\n",
    "\n",
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "        source_fpfh, target_fpfh, voxel_size)\n",
    "print(result_ransac)\n",
    "draw_registration_result(source_down, target_down,\n",
    "        result_ransac.transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"global_registration_output.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local refinement\n",
    "For performance reason, the global registration is only performed on a heavily down-sampled point cloud. The result is also not tight. We use Point-to-plane ICP to further refine the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "    print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "    print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    # further refine the ransac result using point-to-plane icp registration\n",
    "    result = registration_icp(source, target, distance_threshold,\n",
    "            result_ransac.transformation,\n",
    "            TransformationEstimationPointToPlane())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Point-to-plane ICP registration is applied on original point\n",
      "   clouds to refine the alignment. This time we use a strict\n",
      "   distance threshold 0.020.\n",
      "RegistrationResult with fitness = 0.621033, inlier_rmse = 0.006565, and correspondence_set size of 123483\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "result_icp = refine_registration(source, target,\n",
    "        source_fpfh, target_fpfh, voxel_size)\n",
    "print(result_icp)\n",
    "draw_registration_result(source, target, result_icp.transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"refine_t12.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs a tight alignment. This summarizes a complete pairwise registration workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
