{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiway registration\n",
    "ref: http://www.open3d.org/docs/tutorial/Advanced/multiway_registration.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"multi_registration_t14.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/Python/Tutorial/Advanced/multiway_registration.py\n",
    "\n",
    "from open3d import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper visualization function\n",
    "This function visualizes a target point cloud, and a source point cloud transformed with an alignment transformation. The target point cloud and the source point cloud are painted with cyan and yellow colors respectively. The more and tighter the two point clouds overlap with each other, the better the alignment result is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    # Since functions transform() and paint_uniform_color() change the point cloud, \n",
    "    # we call copy.deepcopy() to make copies and protect the original point clouds.\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "The first part of the tutorial script reads three point clouds from files. The point clouds are downsampled and visualized together. They are misaligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_verbosity_level(VerbosityLevel.Debug)\n",
    "pcds = []\n",
    "for i in range(3):\n",
    "    pcd = read_point_cloud(\n",
    "            \"/data/code6/Open3D/build/lib/TestData/ICP/cloud_bin_%d.pcd\" % i)\n",
    "    # downsample\n",
    "    downpcd = voxel_down_sample(pcd, voxel_size = 0.02)\n",
    "    pcds.append(downpcd)\n",
    "# transformation applied, just raw output\n",
    "draw_geometries(pcds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"input_t14.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a pose graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"pg_t14.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "??get_information_matrix_from_point_clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-plane ICP for local registration\n",
      "[[ 0.84053328  0.00666116 -0.54171896  0.64468991]\n",
      " [-0.14723957  0.9650954  -0.21659036  0.80888236]\n",
      " [ 0.52136773  0.26181388  0.81217559 -1.48409964]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Build PoseGraph\n",
      "Apply point-to-plane ICP for local registration\n",
      "[[ 0.97599198 -0.00161051 -0.21780052 -0.04531353]\n",
      " [-0.06004143  0.95923835 -0.27614636  0.82682918]\n",
      " [ 0.20936735  0.28259369  0.93611224 -1.05535812]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Build PoseGraph\n",
      "Apply point-to-plane ICP for local registration\n",
      "[[ 0.95523101 -0.08237749  0.28416136 -0.15207426]\n",
      " [ 0.08663369  0.9962373  -0.00241995 -0.01290785]\n",
      " [-0.28289279  0.02692956  0.95877342  0.41765454]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Build PoseGraph\n"
     ]
    }
   ],
   "source": [
    "# build graph using PoseGraph()\n",
    "pose_graph = PoseGraph()\n",
    "odometry = np.identity(4)\n",
    "# using PoseGraphNode(np.array) to convert transformation matrix for graph node.\n",
    "# then append to list \"pose_graph.nodes\"\n",
    "pose_graph.nodes.append(PoseGraphNode(odometry))\n",
    "\n",
    "n_pcds = len(pcds) # =3\n",
    "# good iterate approach in looping point clouds.\n",
    "for source_id in range(n_pcds): # source_id = 0, 1, 2\n",
    "    for target_id in range(source_id + 1, n_pcds): # 1,2 ; 2 ; \n",
    "        source = pcds[source_id]\n",
    "        target = pcds[target_id]\n",
    "\n",
    "        print(\"Apply point-to-plane ICP for local registration\")\n",
    "        icp_coarse = registration_icp(source, target, 0.3, # max_correspondence_distance=0.3\n",
    "                np.identity(4),\n",
    "                TransformationEstimationPointToPlane())\n",
    "        icp_fine = registration_icp(source, target, 0.03,# max_correspondence_distance=0.03\n",
    "                icp_coarse.transformation,\n",
    "                TransformationEstimationPointToPlane())\n",
    "        transformation_icp = icp_fine.transformation\n",
    "        # computing information matrix from RegistrationResult\n",
    "        information_icp = get_information_matrix_from_point_clouds(\n",
    "                source, target, 0.03, icp_fine.transformation)\n",
    "        print(transformation_icp)\n",
    "\n",
    "        draw_registration_result(source, target, np.identity(4))\n",
    "        print(\"Build PoseGraph\")\n",
    "        if target_id == source_id + 1: # odometry case\n",
    "            odometry = np.dot(transformation_icp, odometry)\n",
    "            pose_graph.nodes.append( # append node (odometry)\n",
    "                    PoseGraphNode(np.linalg.inv(odometry)))\n",
    "            pose_graph.edges.append(\n",
    "                    PoseGraphEdge(source_id, target_id,\n",
    "                    transformation_icp, information_icp, uncertain = False))# classify as \"Odometry edges\"\n",
    "        else: # loop closure case\n",
    "            pose_graph.edges.append(\n",
    "                    PoseGraphEdge(source_id, target_id,\n",
    "                    transformation_icp, information_icp, uncertain = True))# classify as \"Loop closure edge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yellow: source<br>\n",
    "cyan(blue): target\n",
    "<img style=\"float: left;\" src=\"0_1.png\">\n",
    "<img style=\"float: left;\" src=\"0_2.png\">\n",
    "<img style=\"float: left;\" src=\"1_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize a pose graph\n",
    "<img style=\"float: left;\" src=\"optim_pg.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing PoseGraph ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimizing PoseGraph ...\")\n",
    "option = GlobalOptimizationOption(\n",
    "        max_correspondence_distance = 0.03, # correspondence threshold\n",
    "        edge_prune_threshold = 0.25, # threshold for pruning outlier edges\n",
    "        reference_node = 0) # node id==0 to be considered to be global space.\n",
    "# perform pose graph optimization\n",
    "global_optimization(pose_graph,\n",
    "        GlobalOptimizationLevenbergMarquardt(), # use LevenbergMarquardt method\n",
    "        GlobalOptimizationConvergenceCriteria(), option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"optim_pg_output.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize optimization\n",
    "The global optimization performs twice on the pose graph. The first pass optimizes poses for the original pose graph taking all edges into account and does its best to distinguish false alignments among uncertain edges. These false alignments have small line process weights, and they are pruned after the first pass. The second pass runs without them and produces a tight global alignment. In this example, all the edges are considered as true alignments, hence the second pass terminates immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform points and display\n",
      "[[ 1.00000000e+00  1.08420217e-19  0.00000000e+00  0.00000000e+00]\n",
      " [ 9.48676901e-20  1.00000000e+00 -1.73472348e-18 -1.73472348e-18]\n",
      " [ 0.00000000e+00  8.67361738e-19  1.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[[ 0.843625   -0.1476311   0.51623824  0.33592352]\n",
      " [ 0.00507615  0.96360772  0.26727214 -0.39648186]\n",
      " [-0.53690884 -0.22285696  0.81367295  1.72898284]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[ 0.97043745 -0.0743457   0.22961679  0.37036442]\n",
      " [ 0.00444853  0.95672239  0.29096817 -0.51091179]\n",
      " [-0.24131175 -0.28134495  0.92876997  1.27213222]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Transform points and display\")\n",
    "for point_id in range(n_pcds):\n",
    "    print(pose_graph.nodes[point_id].pose)\n",
    "    pcds[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "draw_geometries(pcds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"optim_pg_result.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this tutorial demonstrates multiway registration for point clouds. The same procedure can be applied to <b>RGBD images</b>. See Make fragments for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
